# -*- coding: utf-8 -*-
"""4a. Classification_MNIST_CNN_All_Convolutional.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zLldf_HObb2Lcu941YDw7w-E7MkTqmbr

### Load tensorflow
"""

import tensorflow as tf
tf.set_random_seed(42)

tf.__version__

"""### Collect Data
We will use MNIST dataset for this exercise. This dataset contains images of hand written numbers with each image being a black & white picture of size 28x28. We will download the data using tensorflow API. The dataset has 60,000 training examples and 10,000 test examples. Please note that images have already been converted to numpy arrays.
"""

#Download dataset
(trainX, trainY),(testX, testY) = tf.keras.datasets.mnist.load_data()

#Check number of training examples and size of each example
trainX.shape

#Check number of test examples and size of each example
testX.shape

#Let's review the data
import matplotlib.pyplot as plt
import numpy as np
img_num = np.random.randint(0, testX.shape[0]) #Get a random integer between 0 and number of examples in test dataset
plt.imshow(testX[img_num],cmap='gray') #Show the image from test dataset
plt.suptitle('Number: ' + str(testY[img_num]))
plt.show()

"""### Convert Output label to multiple values"""

#Check current label size
testY[0]

#Convert labels to one hot encoding
trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)
testY = tf.keras.utils.to_categorical(testY, num_classes=10)

#Now check the label size
trainY[0]

"""## Build the Graph"""

#Clear any existing model in memory
tf.keras.backend.clear_session()

#Initialize model, reshape & normalize data
model = tf.keras.models.Sequential()

#Reshape data from 2D (28,28) to 3D (28, 28, 1)
model.add(tf.keras.layers.Reshape((28,28,1),input_shape=(28,28,)))

#normalize data
model.add(tf.keras.layers.BatchNormalization())

"""### Apply Convolutional Layers, MaxPooling"""

#Add first convolutional layer
model.add(tf.keras.layers.Conv2D(32, #Number of filters 
                                 kernel_size=(3,3), #Size of the filter
                                 activation='relu'))

#normalize data
model.add(tf.keras.layers.BatchNormalization())

#Add second convolutional layer
model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu', strides=(2,2), padding='same'))

#normalize data
model.add(tf.keras.layers.BatchNormalization())

#Check model output at current stage
model.output

"""### Add layers for Classification"""

#Add layer with 10 filters
model.add(tf.keras.layers.Conv2D(10, kernel_size=(1,1), activation='relu'))

#Check model output at current stage
model.output

#Use Global Average pooling layer to reduce number of outputs to 10
model.add(tf.keras.layers.GlobalAveragePooling2D())

#Check model output at current stage
model.output

#Output layer
model.add(tf.keras.layers.Activation('softmax'))

model.compile(optimizer='adam', 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])

model.summary()

"""## Train the model"""

#Train the model
model.fit(trainX,trainY,          
          validation_data=(testX,testY),
          epochs=30,
          batch_size=32)

model.save('mnist_cnn_v1.h5')
model.save_weights('mnist_cnn_weights_v1.h5')